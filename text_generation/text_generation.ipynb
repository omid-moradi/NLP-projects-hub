{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALS6ACfP-TPI",
        "outputId": "956fac9a-387c-4cd3-afef-7e7c3fe1828b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pujMhnz2-RC6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aavnuByVymwK"
      },
      "outputs": [],
      "source": [
        "text_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/2/10-Text Generator(Attar's Poem)/Sample/naserkhosro.txt\"\n",
        "text = open(text_path, 'rb').read().decode(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfnnmEFe-RC_",
        "outputId": "21cd1b47-e991-4143-b653-4c68c9df28fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 633429 characters\n"
          ]
        }
      ],
      "source": [
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duhg9NrUymwO",
        "outputId": "e257113d-0a65-4a41-984d-093f95ee7078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ای قبهٔ گردندهٔ بی روزن خضرا\n",
            "با قامت فرتوتی و با قوت برنا\n",
            "فرزند توایم ای فلک، ای مادر بدمهر\n",
            "ای مادر ما چونکه همی کین کشی از ما؟\n",
            "فرزند تو این تیره تن خامش خاکی است\n",
            "پاکیزه خرد نیست نه این جوهر گویا\n",
            "تن خانهٔ این گوهر والای شریف است\n",
            "تو مادر این خانهٔ این\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlCgQBRVymwR",
        "outputId": "adf8a747-846e-425a-ce98-71d46edf870b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## Process the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjSVAlWzf-N"
      },
      "source": [
        "### Vectorize the text\n",
        "\n",
        "Before training, we need to map strings to a numerical representation. Create two lookup tables: one mapping characters to numbers, and another for numbers to characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IalZLbvOzf-F"
      },
      "outputs": [],
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZfqhkYCymwX"
      },
      "source": [
        "Now we have an integer representation for each character. Notice that we mapped the character as indexes from 0 to `len(unique)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYyNlCNXymwY",
        "outputId": "7c4edfc1-933c-4225-9534-65aaeb85b4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '(' :   3,\n",
            "  ')' :   4,\n",
            "  '.' :   5,\n",
            "  ':' :   6,\n",
            "  '«' :   7,\n",
            "  '»' :   8,\n",
            "  '،' :   9,\n",
            "  '؛' :  10,\n",
            "  '؟' :  11,\n",
            "  'ء' :  12,\n",
            "  'آ' :  13,\n",
            "  'ؤ' :  14,\n",
            "  'ئ' :  15,\n",
            "  'ا' :  16,\n",
            "  'ب' :  17,\n",
            "  'ة' :  18,\n",
            "  'ت' :  19,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1VKcQHcymwb",
        "outputId": "3e4e68be-88a4-4961-91fc-0f7f23c0f184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'ای قبهٔ گردندهٔ بی روزن خضرا\\nب' ---- characters mapped to int ---- > [16 49  1 37 17 41 43  1 48 26 24 40 24 41 43  1 17 49  1 26 42 27 40  1\n",
            " 23 31 26 16  0 17]\n"
          ]
        }
      ],
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:30]), text_as_int[:30]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Create training examples and targets\n",
        "\n",
        "Next divide the text into example sequences. Each input sequence will contain `seq_length` characters from the text.\n",
        "\n",
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "So break the text into chunks of `seq_length+1`. For example, say `seq_length` is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
        "\n",
        "To do this first use the `tf.data.Dataset.from_tensor_slices` function to convert the text vector into a stream of character indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0UHJDA39zf-O"
      },
      "outputs": [],
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "H-zFw5O6-RDJ"
      },
      "outputs": [],
      "source": [
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RplQyLSA-RDJ",
        "outputId": "6584acd4-19d7-4af2-83f4-aaa765c17482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 ا\n",
            "49 ی\n",
            "1  \n",
            "37 ق\n",
            "17 ب\n",
            "41 ه\n",
            "43 ٔ\n",
            "1  \n",
            "48 گ\n",
            "26 ر\n"
          ]
        }
      ],
      "source": [
        "for i in char_dataset.take(10):\n",
        "    print(i.numpy(), idx2char[i.numpy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZSYAcQV8OGP"
      },
      "source": [
        "### Sliding Window for Sequence Generation\n",
        "\n",
        "Instead of using simple batching, we use the **sliding window** method to generate overlapping sequences of length `seq_length + 1`.  \n",
        "This ensures that every character in the text contributes to multiple training samples, preserving the continuity of the text.  \n",
        "Compared to fixed-size batching, this approach creates **richer and more context-aware training data**, helping the model better capture character-level dependencies in the text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "l4hkDU3i7ozi"
      },
      "outputs": [],
      "source": [
        "# Sliding window: ساخت پنجره‌های طول ثابت با گام 1\n",
        "sequences = char_dataset.window(size=seq_length + 1, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# هر پنجره را به یک تانسور تبدیل می‌کنیم تا بتوان پردازشش کرد\n",
        "sequences = sequences.flat_map(lambda window: window.batch(seq_length + 1))"
      ],
      "metadata": {
        "id": "C1krUAxmGdpl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbLcIPBj_mWZ"
      },
      "source": [
        "For each sequence, duplicate and shift it to form the input and target text by using the `map` method to apply a simple function to each batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiCopyGZymwi"
      },
      "source": [
        "Print the first examples input and target values:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# بررسی ۳ نمونه اولیه\n",
        "for input_example, target_example in dataset.take(3):\n",
        "    print('Input: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target:', repr(''.join(idx2char[target_example.numpy()])))\n",
        "    print('-' * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZbGZwW3GGEy",
        "outputId": "222e87de-8321-4ea2-ac63-3f25d0afb225"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  'ای قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر '\n",
            "Target: 'ی قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر م'\n",
            "------------------------------\n",
            "Input:  'ی قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر م'\n",
            "Target: ' قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر ما'\n",
            "------------------------------\n",
            "Input:  ' قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر ما'\n",
            "Target: 'قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر ما '\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}