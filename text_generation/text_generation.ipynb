{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALS6ACfP-TPI",
        "outputId": "b7df26c7-2dbb-4329-edfe-e3f4ca903c22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pujMhnz2-RC6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "aavnuByVymwK"
      },
      "outputs": [],
      "source": [
        "text_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/2/10-Text Generator(Attar's Poem)/Sample/naserkhosro.txt\"\n",
        "text = open(text_path, 'rb').read().decode(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfnnmEFe-RC_",
        "outputId": "21f089fa-d34b-4913-f1f7-25efcd8b4004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 633429 characters\n"
          ]
        }
      ],
      "source": [
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duhg9NrUymwO",
        "outputId": "95ffde93-6ec6-4fcf-ee3e-00a4b29cf279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ای قبهٔ گردندهٔ بی روزن خضرا\n",
            "با قامت فرتوتی و با قوت برنا\n",
            "فرزند توایم ای فلک، ای مادر بدمهر\n",
            "ای مادر ما چونکه همی کین کشی از ما؟\n",
            "فرزند تو این تیره تن خامش خاکی است\n",
            "پاکیزه خرد نیست نه این جوهر گویا\n",
            "تن خانهٔ این گوهر والای شریف است\n",
            "تو مادر این خانهٔ این\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlCgQBRVymwR",
        "outputId": "95ca3518-5d5f-4549-b410-22a98644d3a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## Process the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjSVAlWzf-N"
      },
      "source": [
        "### Vectorize the text\n",
        "\n",
        "Before training, we need to map strings to a numerical representation. Create two lookup tables: one mapping characters to numbers, and another for numbers to characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IalZLbvOzf-F"
      },
      "outputs": [],
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZfqhkYCymwX"
      },
      "source": [
        "Now we have an integer representation for each character. Notice that we mapped the character as indexes from 0 to `len(unique)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYyNlCNXymwY",
        "outputId": "2b09c5d9-473c-4309-f41b-746bf633d926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '(' :   3,\n",
            "  ')' :   4,\n",
            "  '.' :   5,\n",
            "  ':' :   6,\n",
            "  '«' :   7,\n",
            "  '»' :   8,\n",
            "  '،' :   9,\n",
            "  '؛' :  10,\n",
            "  '؟' :  11,\n",
            "  'ء' :  12,\n",
            "  'آ' :  13,\n",
            "  'ؤ' :  14,\n",
            "  'ئ' :  15,\n",
            "  'ا' :  16,\n",
            "  'ب' :  17,\n",
            "  'ة' :  18,\n",
            "  'ت' :  19,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1VKcQHcymwb",
        "outputId": "b61cc73d-b386-4bd6-f8f3-1c936a7d19a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'ای قبهٔ گردندهٔ بی روزن خضرا\\nب' ---- characters mapped to int ---- > [16 49  1 37 17 41 43  1 48 26 24 40 24 41 43  1 17 49  1 26 42 27 40  1\n",
            " 23 31 26 16  0 17]\n"
          ]
        }
      ],
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:30]), text_as_int[:30]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Create training examples and targets\n",
        "\n",
        "Next divide the text into example sequences. Each input sequence will contain `seq_length` characters from the text.\n",
        "\n",
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "So break the text into chunks of `seq_length+1`. For example, say `seq_length` is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
        "\n",
        "To do this first use the `tf.data.Dataset.from_tensor_slices` function to convert the text vector into a stream of character indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0UHJDA39zf-O"
      },
      "outputs": [],
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "H-zFw5O6-RDJ"
      },
      "outputs": [],
      "source": [
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RplQyLSA-RDJ",
        "outputId": "256eaa7c-9ffa-470d-bd69-36c1ecb7e078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ا\n",
            "ی\n",
            " \n",
            "ق\n",
            "ب\n"
          ]
        }
      ],
      "source": [
        "for i in char_dataset.take(5):\n",
        "    print(idx2char[i.numpy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZSYAcQV8OGP"
      },
      "source": [
        "The `batch` method lets us easily convert these individual characters to sequences of the desired size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "l4hkDU3i7ozi"
      },
      "outputs": [],
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZc_Lb0B-RDK",
        "outputId": "cb1716d8-7b32-4f55-ea6f-36809894e79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'ای قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر م'\n",
            "===\n",
            "'ا چونکه همی کین کشی از ما؟\\nفرزند تو این تیره تن خامش خاکی است\\nپاکیزه خرد نیست نه این جوهر گویا\\nتن خان'\n",
            "===\n",
            "'هٔ این گوهر والای شریف است\\nتو مادر این خانهٔ این گوهر والا\\nچون کار خود امروز در این خانه بسازم\\nمفرد ب'\n",
            "===\n",
            "'روم، خانه سپارم به تو فردا\\nزندان تو آمد پسرا این تن و، زندان\\nزیبا نشود گرچه بپوشیش به دیبا\\nدیبای سخن '\n",
            "===\n",
            "'پوش به جان بر، که تو را جان\\nهرگز نشود ای پسر از دیبا زیبا\\nاین بند نبینی که خداوند نهاده است\\nبر ما که '\n",
            "===\n"
          ]
        }
      ],
      "source": [
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2char[item.numpy()])))\n",
        "    print(\"===\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbLcIPBj_mWZ"
      },
      "source": [
        "For each sequence, duplicate and shift it to form the input and target text by using the `map` method to apply a simple function to each batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiCopyGZymwi"
      },
      "source": [
        "Print the first examples input and target values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNbw-iR0ymwj",
        "outputId": "385f0e4c-631f-4fe8-ad6a-36cf7624a844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  'ای قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر '\n",
            "Target data: 'ی قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر م'\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eBu9WZG84i0",
        "outputId": "7bc6c5de-ce11-4035-db91-302ad1e8d0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step    0\n",
            "  input: 16 (np.str_('ا'))\n",
            "  expected output: 49 (np.str_('ی'))\n",
            "Step    1\n",
            "  input: 49 (np.str_('ی'))\n",
            "  expected output: 1 (np.str_(' '))\n",
            "Step    2\n",
            "  input: 1 (np.str_(' '))\n",
            "  expected output: 37 (np.str_('ق'))\n",
            "Step    3\n",
            "  input: 37 (np.str_('ق'))\n",
            "  expected output: 17 (np.str_('ب'))\n",
            "Step    4\n",
            "  input: 17 (np.str_('ب'))\n",
            "  expected output: 41 (np.str_('ه'))\n"
          ]
        }
      ],
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdfPmdqzf-R"
      },
      "source": [
        "### Create training batches\n",
        "\n",
        "We used `tf.data` to split the text into manageable sequences. But before feeding this data into the model, we need to shuffle the data and pack it into batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2pGotuNzf-S",
        "outputId": "94cf1a9b-83de-4fea-f145-22d464216c57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(32, 100), dtype=tf.int64, name=None), TensorSpec(shape=(32, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## Build The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "Use `tf.keras.Sequential` to define the model. For this simple example three layers are used to define our model:\n",
        "\n",
        "* `tf.keras.layers.Embedding`: The input layer. A trainable lookup table that will map the numbers of each character to a vector with `embedding_dim` dimensions;\n",
        "* `tf.keras.layers.GRU`: A type of RNN with size `units=rnn_units` (You can also use a LSTM layer here.)\n",
        "* `tf.keras.layers.Dense`: The output layer, with `vocab_size` outputs.\n",
        "\n",
        "\n",
        "\n",
        "+ return_sequences: Whether to return the last output\n",
        "    in the output sequence, or the full sequence.\n",
        "    \n",
        "+ return_state: Whether to return the last state\n",
        "    in addition to the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "MtCrdfzEI2N0"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    inputs = tf.keras.Input(batch_shape=(batch_size, None))\n",
        "    x = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    x = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True)(x)\n",
        "    outputs = tf.keras.layers.Dense(vocab_size)(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "wwsrpOik5zhv"
      },
      "outputs": [],
      "source": [
        "model = build_model(\n",
        "                    vocab_size = len(vocab),\n",
        "                    embedding_dim = embedding_dim,\n",
        "                    rnn_units = rnn_units,\n",
        "                    batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "## Try the model\n",
        "\n",
        "Now run the model to see that it behaves as expected.\n",
        "\n",
        "First check the shape of the output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-_70kKAPrPU",
        "outputId": "5eed29b8-1a68-4573-b5c5-3b7872ad064f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "(32, 100, 50)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    print(input_example_batch.shape)\n",
        "    example_batch_predictions = model.predict(input_example_batch)\n",
        "    print(example_batch_predictions.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NzLBi4VM4o"
      },
      "source": [
        "In the above example the sequence length of the input is `100` but the model can be run on inputs of any length:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "vPGmAAXmVLGC",
        "outputId": "c12ab707-a064-4867-bc8c-8790e8410f41"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;45mNone\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m12,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m51,250\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,250</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,002,354\u001b[0m (15.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,002,354</span> (15.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,002,354\u001b[0m (15.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,002,354</span> (15.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwv0gEkURfx1"
      },
      "source": [
        "To get actual predictions from the model we need to sample from the output distribution, to get actual character indices. This distribution is defined by the logits over the character vocabulary.\n",
        "\n",
        "Note: It is important to _sample_ from this distribution as taking the _argmax_ of the distribution can easily get the model stuck in a loop.\n",
        "\n",
        "Try it for the first example in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L8EK4DC-RDP",
        "outputId": "ed6697f4-f7ec-4662-e414-23072e5be7ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 7.8392401e-04, -1.4282959e-02, -5.0824303e-03, ...,\n",
              "          2.0767143e-03, -1.3874118e-02, -3.2270160e-03],\n",
              "        [ 6.9255042e-03, -2.4337061e-03,  2.6898317e-03, ...,\n",
              "         -1.8207788e-03, -3.3074433e-03, -4.8244251e-03],\n",
              "        [-5.5788299e-03,  2.0956341e-04, -3.7915658e-03, ...,\n",
              "          3.4684665e-04, -3.6644940e-03, -5.7875793e-03],\n",
              "        ...,\n",
              "        [ 7.3813619e-03,  4.0533924e-03, -9.2794299e-03, ...,\n",
              "          1.6204957e-02, -1.1179513e-02, -1.3463888e-03],\n",
              "        [ 5.5944417e-03,  1.1395666e-02,  6.0529732e-03, ...,\n",
              "          9.6706748e-03,  9.0573281e-03, -1.3590965e-02],\n",
              "        [-6.4886170e-03,  1.0035698e-02, -2.0695808e-03, ...,\n",
              "          8.4276004e-03,  1.5949975e-03, -1.2189129e-02]],\n",
              "\n",
              "       [[ 7.8392401e-04, -1.4282959e-02, -5.0824303e-03, ...,\n",
              "          2.0767143e-03, -1.3874118e-02, -3.2270160e-03],\n",
              "        [-8.9413347e-03, -5.7290751e-03, -6.5885503e-03, ...,\n",
              "          2.8229016e-03, -8.9362916e-03, -4.2078095e-03],\n",
              "        [-1.3693246e-02,  2.4129183e-03, -3.5731276e-03, ...,\n",
              "          1.1821918e-02, -8.4266700e-03, -5.4504322e-03],\n",
              "        ...,\n",
              "        [-4.1131540e-03,  1.0259091e-03,  1.6701100e-03, ...,\n",
              "         -1.8466115e-03,  3.5101774e-03, -6.8218415e-03],\n",
              "        [-1.0740548e-02,  6.7511853e-04,  1.9554296e-03, ...,\n",
              "         -3.1861379e-03,  8.7835919e-04,  3.3663549e-03],\n",
              "        [-3.8620317e-03, -1.4029894e-02, -2.3609016e-03, ...,\n",
              "          1.5581703e-03, -1.2270205e-02, -1.8249493e-03]],\n",
              "\n",
              "       [[ 6.2371283e-03, -6.5454403e-03, -7.4412427e-03, ...,\n",
              "          1.1788827e-03, -2.6199566e-03,  3.5384099e-03],\n",
              "        [ 1.6663584e-03, -7.6835803e-03, -9.7982045e-03, ...,\n",
              "          2.7940921e-03, -7.0725065e-03, -4.5203506e-03],\n",
              "        [-9.5010186e-03, -1.2774514e-03, -9.4964551e-03, ...,\n",
              "          2.3700558e-03, -4.4289189e-03, -3.7969276e-03],\n",
              "        ...,\n",
              "        [ 2.4754058e-03,  8.9694783e-03,  1.8748254e-02, ...,\n",
              "         -1.0501957e-03,  1.3032525e-02, -5.0022816e-03],\n",
              "        [ 1.1182859e-02,  1.7041748e-02,  5.2550868e-03, ...,\n",
              "          9.6607618e-03, -1.7644120e-03, -3.7586638e-03],\n",
              "        [-4.2289766e-03,  1.2963094e-02, -2.3241807e-03, ...,\n",
              "          9.2811622e-03, -3.9025978e-03, -6.5456708e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.1460067e-02,  1.7705141e-05,  1.3980853e-03, ...,\n",
              "         -6.8003843e-03,  6.6877566e-03, -9.2370193e-03],\n",
              "        [ 1.5378267e-02,  1.2040434e-02, -1.0779471e-03, ...,\n",
              "          7.6884804e-03, -2.7082777e-03, -1.1792476e-03],\n",
              "        [ 1.3242686e-02,  1.3459434e-02,  7.6111611e-03, ...,\n",
              "          4.6995534e-03,  6.1672968e-03,  1.4468873e-02],\n",
              "        ...,\n",
              "        [-8.6601218e-03,  1.7826492e-04,  6.4213574e-04, ...,\n",
              "         -7.2578304e-03,  2.2629201e-03, -5.8564562e-03],\n",
              "        [-1.9650156e-02, -9.3583083e-03, -3.6539081e-03, ...,\n",
              "         -6.9683585e-03,  4.9833143e-03,  9.1791507e-03],\n",
              "        [-7.4740588e-03,  2.5580111e-03,  7.5017698e-03, ...,\n",
              "         -6.2124999e-03,  1.8988408e-02, -6.5020137e-03]],\n",
              "\n",
              "       [[ 6.3651316e-03,  5.4148389e-03,  7.2465963e-03, ...,\n",
              "         -2.8721904e-03,  6.2373881e-03,  1.4349367e-02],\n",
              "        [ 2.6300773e-02,  1.5680125e-02,  7.8964652e-04, ...,\n",
              "         -7.1899625e-03,  1.9418119e-02,  1.5588143e-02],\n",
              "        [ 3.4125049e-02,  9.0842380e-04,  2.2450716e-03, ...,\n",
              "         -1.5252801e-03,  1.9937404e-02,  2.5872318e-03],\n",
              "        ...,\n",
              "        [-4.7170026e-03, -1.6212417e-04, -1.3867151e-03, ...,\n",
              "         -4.8793778e-03,  4.2104609e-03,  2.0518491e-02],\n",
              "        [-1.6928418e-04,  3.6326994e-03, -2.2686529e-03, ...,\n",
              "          4.8722406e-03,  1.3986309e-03,  9.8698009e-03],\n",
              "        [-9.8459236e-04, -1.3807058e-02, -6.2810406e-03, ...,\n",
              "          1.9623383e-03, -1.2004672e-02, -6.9135753e-04]],\n",
              "\n",
              "       [[-1.2079779e-02, -8.2535641e-03,  6.6392422e-03, ...,\n",
              "          1.6417718e-03, -2.7066173e-03, -3.5613158e-03],\n",
              "        [-1.4002473e-02, -1.6304664e-05,  5.9948256e-04, ...,\n",
              "          1.0680277e-03, -1.1856218e-03, -5.9641567e-03],\n",
              "        [-1.9357260e-04, -6.2454697e-03, -6.7875516e-03, ...,\n",
              "          1.7826998e-03, -1.7198278e-03, -1.8052880e-03],\n",
              "        ...,\n",
              "        [ 4.4156676e-03,  6.7493925e-03,  7.5086094e-03, ...,\n",
              "          9.3207043e-03,  3.4709119e-03, -8.0267619e-03],\n",
              "        [-6.5675359e-03,  5.0890306e-03, -7.9188356e-04, ...,\n",
              "          5.4366104e-03, -1.2934393e-03, -7.8659980e-03],\n",
              "        [-1.9005800e-03, -1.2468511e-02, -5.6726988e-03, ...,\n",
              "          5.0779060e-03, -1.4764018e-02, -9.3064569e-03]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "example_batch_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V4MfFg0RQJg",
        "outputId": "97112e88-310e-4465-959e-575355fa19d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 1), dtype=int64, numpy=\n",
              "array([[32],\n",
              "       [43],\n",
              "       [ 6],\n",
              "       [14],\n",
              "       [43],\n",
              "       [ 8],\n",
              "       [30],\n",
              "       [13],\n",
              "       [29],\n",
              "       [45],\n",
              "       [40],\n",
              "       [18],\n",
              "       [ 3],\n",
              "       [34],\n",
              "       [27],\n",
              "       [46],\n",
              "       [ 6],\n",
              "       [45],\n",
              "       [47],\n",
              "       [23],\n",
              "       [18],\n",
              "       [34],\n",
              "       [12],\n",
              "       [23],\n",
              "       [12],\n",
              "       [28],\n",
              "       [21],\n",
              "       [13],\n",
              "       [39],\n",
              "       [ 5],\n",
              "       [41],\n",
              "       [ 8],\n",
              "       [46],\n",
              "       [ 9],\n",
              "       [37],\n",
              "       [21],\n",
              "       [19],\n",
              "       [45],\n",
              "       [38],\n",
              "       [ 2],\n",
              "       [22],\n",
              "       [36],\n",
              "       [45],\n",
              "       [25],\n",
              "       [18],\n",
              "       [48],\n",
              "       [18],\n",
              "       [17],\n",
              "       [27],\n",
              "       [31],\n",
              "       [39],\n",
              "       [ 0],\n",
              "       [ 9],\n",
              "       [38],\n",
              "       [29],\n",
              "       [ 6],\n",
              "       [49],\n",
              "       [27],\n",
              "       [ 0],\n",
              "       [11],\n",
              "       [18],\n",
              "       [35],\n",
              "       [11],\n",
              "       [37],\n",
              "       [39],\n",
              "       [29],\n",
              "       [17],\n",
              "       [44],\n",
              "       [ 6],\n",
              "       [13],\n",
              "       [19],\n",
              "       [46],\n",
              "       [46],\n",
              "       [31],\n",
              "       [44],\n",
              "       [13],\n",
              "       [21],\n",
              "       [ 0],\n",
              "       [31],\n",
              "       [ 6],\n",
              "       [19],\n",
              "       [34],\n",
              "       [ 3],\n",
              "       [ 8],\n",
              "       [ 2],\n",
              "       [ 4],\n",
              "       [30],\n",
              "       [ 9],\n",
              "       [31],\n",
              "       [21],\n",
              "       [24],\n",
              "       [16],\n",
              "       [16],\n",
              "       [26],\n",
              "       [46],\n",
              "       [20],\n",
              "       [28],\n",
              "       [31],\n",
              "       [28],\n",
              "       [ 1]])>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM1Vbxs_URw5"
      },
      "source": [
        "This gives us, at each timestep, a prediction of the next character index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqFMUQc_UFgM",
        "outputId": "5a87c5b1-495d-430d-f62d-251c97dc28c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([32, 43,  6, 14, 43,  8, 30, 13, 29, 45, 40, 18,  3, 34, 27, 46,  6,\n",
              "       45, 47, 23, 18, 34, 12, 23, 12, 28, 21, 13, 39,  5, 41,  8, 46,  9,\n",
              "       37, 21, 19, 45, 38,  2, 22, 36, 45, 25, 18, 48, 18, 17, 27, 31, 39,\n",
              "        0,  9, 38, 29,  6, 49, 27,  0, 11, 18, 35, 11, 37, 39, 29, 17, 44,\n",
              "        6, 13, 19, 46, 46, 31, 44, 13, 21,  0, 31,  6, 19, 34,  3,  8,  2,\n",
              "        4, 30,  9, 31, 21, 24, 16, 16, 26, 46, 20, 28, 31, 28,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLtsP3mUhCG"
      },
      "source": [
        "Decode these to see the text predicted by this untrained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWcFwPwLSo05",
        "outputId": "cedb707a-652a-40b7-c8f3-2cc8baa37acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'ای قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر '\n",
            "\n",
            "Next Char Predictions: \n",
            " 'طٔ:ؤٔ»صآشچنة(عزژ:چکخةعءخءسجآم.ه»ژ،قجتچل!حفچذةگةبزضم\\n،لش:یز\\n؟ةغ؟قمشبپ:آتژژضپآج\\nض:تع(»!)ص،ضجداارژثسضس '\n"
          ]
        }
      ],
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}