{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALS6ACfP-TPI",
        "outputId": "956fac9a-387c-4cd3-afef-7e7c3fe1828b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pujMhnz2-RC6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aavnuByVymwK"
      },
      "outputs": [],
      "source": [
        "text_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/2/10-Text Generator(Attar's Poem)/Sample/naserkhosro.txt\"\n",
        "text = open(text_path, 'rb').read().decode(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfnnmEFe-RC_",
        "outputId": "21cd1b47-e991-4143-b653-4c68c9df28fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 633429 characters\n"
          ]
        }
      ],
      "source": [
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duhg9NrUymwO",
        "outputId": "e257113d-0a65-4a41-984d-093f95ee7078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ای قبهٔ گردندهٔ بی روزن خضرا\n",
            "با قامت فرتوتی و با قوت برنا\n",
            "فرزند توایم ای فلک، ای مادر بدمهر\n",
            "ای مادر ما چونکه همی کین کشی از ما؟\n",
            "فرزند تو این تیره تن خامش خاکی است\n",
            "پاکیزه خرد نیست نه این جوهر گویا\n",
            "تن خانهٔ این گوهر والای شریف است\n",
            "تو مادر این خانهٔ این\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlCgQBRVymwR",
        "outputId": "adf8a747-846e-425a-ce98-71d46edf870b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## Process the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjSVAlWzf-N"
      },
      "source": [
        "### Vectorize the text\n",
        "\n",
        "Before training, we need to map strings to a numerical representation. Create two lookup tables: one mapping characters to numbers, and another for numbers to characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IalZLbvOzf-F"
      },
      "outputs": [],
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZfqhkYCymwX"
      },
      "source": [
        "Now we have an integer representation for each character. Notice that we mapped the character as indexes from 0 to `len(unique)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYyNlCNXymwY",
        "outputId": "7c4edfc1-933c-4225-9534-65aaeb85b4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '(' :   3,\n",
            "  ')' :   4,\n",
            "  '.' :   5,\n",
            "  ':' :   6,\n",
            "  '«' :   7,\n",
            "  '»' :   8,\n",
            "  '،' :   9,\n",
            "  '؛' :  10,\n",
            "  '؟' :  11,\n",
            "  'ء' :  12,\n",
            "  'آ' :  13,\n",
            "  'ؤ' :  14,\n",
            "  'ئ' :  15,\n",
            "  'ا' :  16,\n",
            "  'ب' :  17,\n",
            "  'ة' :  18,\n",
            "  'ت' :  19,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1VKcQHcymwb",
        "outputId": "3e4e68be-88a4-4961-91fc-0f7f23c0f184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'ای قبهٔ گردندهٔ بی روزن خضرا\\nب' ---- characters mapped to int ---- > [16 49  1 37 17 41 43  1 48 26 24 40 24 41 43  1 17 49  1 26 42 27 40  1\n",
            " 23 31 26 16  0 17]\n"
          ]
        }
      ],
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:30]), text_as_int[:30]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Create training examples and targets\n",
        "\n",
        "Next divide the text into example sequences. Each input sequence will contain `seq_length` characters from the text.\n",
        "\n",
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "So break the text into chunks of `seq_length+1`. For example, say `seq_length` is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
        "\n",
        "To do this first use the `tf.data.Dataset.from_tensor_slices` function to convert the text vector into a stream of character indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0UHJDA39zf-O"
      },
      "outputs": [],
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "H-zFw5O6-RDJ"
      },
      "outputs": [],
      "source": [
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RplQyLSA-RDJ",
        "outputId": "6584acd4-19d7-4af2-83f4-aaa765c17482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 ا\n",
            "49 ی\n",
            "1  \n",
            "37 ق\n",
            "17 ب\n",
            "41 ه\n",
            "43 ٔ\n",
            "1  \n",
            "48 گ\n",
            "26 ر\n"
          ]
        }
      ],
      "source": [
        "for i in char_dataset.take(10):\n",
        "    print(i.numpy(), idx2char[i.numpy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZSYAcQV8OGP"
      },
      "source": [
        "### Sliding Window for Sequence Generation\n",
        "\n",
        "Instead of using simple batching, we use the **sliding window** method to generate overlapping sequences of length `seq_length + 1`.  \n",
        "This ensures that every character in the text contributes to multiple training samples, preserving the continuity of the text.  \n",
        "Compared to fixed-size batching, this approach creates **richer and more context-aware training data**, helping the model better capture character-level dependencies in the text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "l4hkDU3i7ozi"
      },
      "outputs": [],
      "source": [
        "# Sliding window: ساخت پنجره‌های طول ثابت با گام 1\n",
        "sequences = char_dataset.window(size=seq_length + 1, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# هر پنجره را به یک تانسور تبدیل می‌کنیم تا بتوان پردازشش کرد\n",
        "sequences = sequences.flat_map(lambda window: window.batch(seq_length + 1))"
      ],
      "metadata": {
        "id": "C1krUAxmGdpl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbLcIPBj_mWZ"
      },
      "source": [
        "For each sequence, duplicate and shift it to form the input and target text by using the `map` method to apply a simple function to each batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiCopyGZymwi"
      },
      "source": [
        "Print the first examples input and target values:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# بررسی ۳ نمونه اولیه\n",
        "for input_example, target_example in dataset.take(3):\n",
        "    print('Input: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target:', repr(''.join(idx2char[target_example.numpy()])))\n",
        "    print('-' * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZbGZwW3GGEy",
        "outputId": "222e87de-8321-4ea2-ac63-3f25d0afb225"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  'ای قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر '\n",
            "Target: 'ی قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر م'\n",
            "------------------------------\n",
            "Input:  'ی قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر م'\n",
            "Target: ' قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر ما'\n",
            "------------------------------\n",
            "Input:  ' قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر ما'\n",
            "Target: 'قبهٔ گردندهٔ بی روزن خضرا\\nبا قامت فرتوتی و با قوت برنا\\nفرزند توایم ای فلک، ای مادر بدمهر\\nای مادر ما '\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Training Batches\n",
        "\n",
        "After generating overlapping input-target pairs using the **sliding window**, we now prepare the data for efficient training.\n",
        "\n",
        "Using `tf.data.Dataset.batch`, we group these pairs into batches of size `BATCH_SIZE`.  \n",
        "This batching ensures optimized parallel processing on GPUs and uniform batch sizes by setting `drop_remainder=True`.  \n",
        "The final `dataset` contains batches of sequences, each ready to be fed into the model during training.\n"
      ],
      "metadata": {
        "id": "4sZO8XjxIfbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYVD48MIIgsa",
        "outputId": "228346f1-7566-4ec1-cfc4-9951e23fd8b8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(64, None), dtype=tf.int64, name=None), TensorSpec(shape=(64, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Model\n",
        "\n",
        "We define the model using `tf.keras.Sequential`, composed of three main layers:\n",
        "\n",
        "- **Embedding Layer**: Maps character indices into dense vectors of size `embedding_dim`. This layer is trainable and learns character-level embeddings.\n",
        "- **GRU Layer**: A type of recurrent neural network that captures sequence dependencies. We use `return_sequences=True` so the model outputs a prediction at each time step. The `stateful=True` option helps the model retain memory across batches for better long-term dependency learning.\n",
        "- **Dense Layer**: Outputs logits for each character in the vocabulary, one per time step.\n",
        "\n",
        "The model is built using the specified `vocab_size`, `embedding_dim`, and `rnn_units`.\n",
        "\n",
        "### Flexible Model Builder with GRU or LSTM\n",
        "\n",
        "We enhance the model-building function to support both GRU and LSTM layers, selectable via a `rnn_type` argument.\n",
        "\n",
        "- `GRU`: Efficient and faster to train\n",
        "- `LSTM`: Better for capturing long-term dependencies\n",
        "\n",
        "Dropout is added to reduce overfitting. Layer normalization is included after the RNN layer for better training stability.\n",
        "This setup allows easy experimentation and comparison between different RNN architectures.\n"
      ],
      "metadata": {
        "id": "iZ70ed46JFqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "vxJJePqRJDWc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size,\n",
        "                rnn_type='GRU', dropout_rate=0.2):\n",
        "\n",
        "    inputs = tf.keras.Input(batch_shape=(batch_size, None), dtype=tf.int32)\n",
        "\n",
        "    x = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "\n",
        "    if rnn_type.upper() == 'GRU':\n",
        "        x = tf.keras.layers.GRU(\n",
        "            rnn_units,\n",
        "            return_sequences=True,\n",
        "            stateful=True,\n",
        "            dropout=dropout_rate,\n",
        "            recurrent_initializer='glorot_uniform'\n",
        "        )(x)\n",
        "    elif rnn_type.upper() == 'LSTM':\n",
        "        x = tf.keras.layers.LSTM(\n",
        "            rnn_units,\n",
        "            return_sequences=True,\n",
        "            stateful=True,\n",
        "            dropout=dropout_rate,\n",
        "            recurrent_initializer='glorot_uniform'\n",
        "        )(x)\n",
        "    else:\n",
        "        raise ValueError(\"rnn_type must be either 'GRU' or 'LSTM'\")\n",
        "\n",
        "    x = tf.keras.layers.LayerNormalization()(x)\n",
        "    outputs = tf.keras.layers.Dense(vocab_size)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "pBDUdtwiJH36"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = build_model(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    rnn_type='GRU'\n",
        ")\n",
        "\n",
        "model_lstm = build_model(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    rnn_type='LSTM'\n",
        ")"
      ],
      "metadata": {
        "id": "IG1p9TwhJIjE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IS5ZY5vCKej2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}